{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf98fcc-ec2a-4792-9ca3-b854b78ed708",
   "metadata": {},
   "source": [
    "# The `ImageROI` class\n",
    "\n",
    "The purpose of the `ImageROI` class is to provide an interface for setting the positions of punch-holes and to do some basic light-dark classification.\n",
    "\n",
    "## Initialization\n",
    "`ImageROI` is intended to be called downstream of `ImageSample`, either by providing the `ImageSample` instance directly or the image. In rare cases, it may not be desired to initialize an `ImageSample` instance, for example, if you are certain that the image you provide already is the sample region. In this case, you can provide either the image (pay attention to the correct type, the type depends on how you load the image) or a file path:\n",
    "\n",
    "```python\n",
    "from msi_workflow import ImageROI\n",
    "\n",
    "roi = ImageROI(path_image_file=r'your\\path\\image_file.png')\n",
    "```\n",
    "or\n",
    "```python\n",
    "import numpy as np\n",
    "from msi_workflow import ImageROI\n",
    "\n",
    "img = np.random.random((100, 100))\n",
    "roi = ImageROI(image=img, image_type='np')\n",
    "```\n",
    "\n",
    "And finally, let's cover the option oF providing the `ImageSample` instance. Assuming that you followed the previous chapter, you can use your saved instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8644f27d-9bbb-48e5-8881-bfcdd72325dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_color: light\n",
      "_hw: (0, 0)\n",
      "_image_original: []\n",
      "_image: []\n",
      "path_folder: C:\\Users\\Yannick Zander\\Promotion\\Test data\n"
     ]
    }
   ],
   "source": [
    "from msi_workflow import ImageSample, ImageROI\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path_folder = r'C:\\Users\\Yannick Zander\\Promotion\\Test data'\n",
    "\n",
    "sample = ImageSample.from_disk(path_folder)\n",
    "roi = ImageROI.from_parent(sample)\n",
    "\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815977d1-ad6c-4115-80b6-c8d3be9048e5",
   "metadata": {},
   "source": [
    "Again the most convenient way is to use a `Project` instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ea32a1-c81b-41e9-8ce8-7d2e3acb3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No age span specified, falling back to more general method\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from msi_workflow import get_project\n",
    "\n",
    "project = get_project(is_MSI=True, path_folder=path_folder, is_laminated=False)\n",
    "project.set_image_roi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689cbdb-bc7e-42b5-a61a-9077531a9dad",
   "metadata": {},
   "source": [
    "You can see a warning that the age span is not specified. This is because the `Project` class immediately executes all steps, but let's examine those steps in a bit more detail\n",
    "\n",
    "## Classifying the image\n",
    "In this step, the image is divided up into background, light, and dark pixels. Background pixels are inherited from the `ImageSample` object, if possible. Otherwise, the Otsu filter is called on the input image. Let's check out what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab2ba36-0b2f-42c0-b2e5-1e5fabb01988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj_color: light\n",
       "_hw: (8592, 24088)\n",
       "_image_original: [[1. 1. 1.]\n",
       " [1. 1. 1.]\n",
       " [1. 1. 1.]]\n",
       "_image: [[1. 1. 1.]\n",
       " [1. 1. 1.]\n",
       " [1. 1. 1.]]\n",
       "path_folder: C:\\Users\\Yannick Zander\\Promotion\\Test data\n",
       "_xywh_ROI: (4673, 1045, 13451, 4682)\n",
       "_image_roi: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.load()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ad319a-8d5b-4c78-ae26-156109f395fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmax which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mroi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_foreground\u001b[49m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\Downloads\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\msi_workflow\\imaging\\main.py:227\u001b[0m, in \u001b[0;36mImage.mask_foreground\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_foreground\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A mask where foreground pixels are True and background pixels are False.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_require_foreground_thr_and_pixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\Downloads\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\msi_workflow\\imaging\\main.py:217\u001b[0m, in \u001b[0;36mImage._require_foreground_thr_and_pixels\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make sure the foreground mask and threshold exists before returning it\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_attr(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mask_foreground\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_foreground_thr_and_pixels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thr_background, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_foreground\n",
      "File \u001b[1;32m~\\Downloads\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\msi_workflow\\imaging\\main.py:202\u001b[0m, in \u001b[0;36mImage.set_foreground_thr_and_pixels\u001b[1;34m(self, thr_method, plts, **_)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_foreground_thr_and_pixels\u001b[39m(\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28mself\u001b[39m, thr_method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124motsu\u001b[39m\u001b[38;5;124m'\u001b[39m, plts: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_\n\u001b[0;32m    185\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    Set threshold for foreground pixels and thresholded binary image.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     mask, thr \u001b[38;5;241m=\u001b[39m \u001b[43mget_foreground_pixels_and_threshold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthr_method\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thr_background: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m thr\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_foreground: np\u001b[38;5;241m.\u001b[39mndarray[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m mask\n",
      "File \u001b[1;32m~\\Downloads\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\msi_workflow\\imaging\\util\\image_helpers.py:263\u001b[0m, in \u001b[0;36mget_foreground_pixels_and_threshold\u001b[1;34m(image, obj_color, method)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m obj_color \u001b[38;5;129;01min\u001b[39;00m obj_colors, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_colors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    262\u001b[0m image_grayscale: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m ensure_image_is_gray(image)\n\u001b[1;32m--> 263\u001b[0m image_grayscale: np\u001b[38;5;241m.\u001b[39mndarray[np\u001b[38;5;241m.\u001b[39muint8] \u001b[38;5;241m=\u001b[39m \u001b[43mrescale_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_grayscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\n\u001b[0;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# define the threshold type depending on the object color\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj_color \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdark\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\Downloads\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\msi_workflow\\imaging\\util\\coordinate_transformations.py:89\u001b[0m, in \u001b[0;36mrescale_values\u001b[1;34m(a, new_min, new_max, old_min, old_max, axis)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m new_max \u001b[38;5;241m>\u001b[39m new_min, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax has to be bigger than min\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     old_max \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_min \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     old_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(a, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\Downloads\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:476\u001b[0m, in \u001b[0;36mnanmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m    471\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmax correctly (gh-8975)\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    478\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[0;32m    479\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation fmax which has no identity"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(roi.mask_foreground)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc435d3-4b22-4f41-a0fe-bad1d0d580b6",
   "metadata": {},
   "source": [
    "We now are entering the area where you have to choose whether your samples are laminated or contain any other distinctive horizons because for samples homogenous in color we can omit steps that try to identify layers. In this example, no lamination can be seen, so we can disable that option using the `is_laminated` keyword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
